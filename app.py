# -*- coding: utf-8 -*-
"""
 Smart Exhibition Pipeline â€” Final Unified Edition + Google Sheets
 Â«Ultimate Smart Exhibition PipelineÂ» + Â«Smart Data PipelineÂ»
- UI  
- Excel Mode , OCR/QR Mode 
- Smart Metadata Injection (Exhibition + Source + Smart Position)
- Fast Mode, Debug Mode, Rate Limiting, Daily Quota
- âœ¨ Batch Processing: Images(5), PDFs(4), Excel(1)
- âœ¨ Quality Control Tracking: User Name, Role, Date, Time
- â˜ï¸ Google Sheets Integration: save in Google Drive

run:
    streamlit run smart_exhibition_pipeline_final.py
"""

import streamlit as st
import subprocess
import os
import sys
import json
import time
import datetime
from pathlib import Path
import pandas as pd
import numpy as np
import re
import shutil

from supabase import create_client, Client


# settings
st.set_page_config(
    page_title="Smart Exhibition Pipeline",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)



# Permanent Google Sheets Link 
FIXED_SHEET_URL = "https://docs.google.com/spreadsheets/d/1OeQbiqvo6v58rcxaoSUidOk0IxSGmL8YCpLnyh27yuE/edit"

st.markdown(f"""
<div style="
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 1.2rem; border-radius: 15px; text-align: center; color: white;
    box-shadow: 0 6px 20px rgba(102,126,234,0.4); margin-bottom: 1.5rem;">
    <h3 style="margin: 0;"> Central Data Sheet</h3>
    <a href="{FIXED_SHEET_URL}" target="_blank"
       style="color: white; background: rgba(255,255,255,0.2);
              padding: 0.6rem 1.2rem; border-radius: 10px;
              text-decoration: none; display: inline-block; margin-top: 0.5rem;">
        ğŸ”— Open in Google Sheets
    </a>
    <p style="margin-top: 0.5rem; font-size: 0.85rem; opacity: 0.9;">
        All processed data are automatically saved here
    </p>
</div>
""", unsafe_allow_html=True)




# UI 
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');
    * { font-family: 'Vazirmatn', sans-serif; }
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 3rem 2rem; border-radius: 20px; text-align: center; margin-bottom: 2rem;
        box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3); animation: slideDown 0.6s ease-out;
    }
    @keyframes slideDown { from { opacity: 0; transform: translateY(-30px);} to { opacity:1; transform: translateY(0);} }
    .main-header h1 { color: white; font-size: 2.8rem; margin: 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.2); }
    .main-header p { color: rgba(255,255,255,0.9); font-size: 1.2rem; margin: 0.5rem 0 0 0; }
    .metric-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 2rem; border-radius: 15px; text-align: center; color: white;
        box-shadow: 0 8px 32px rgba(240, 147, 251, 0.3); transition: transform .3s, box-shadow .3s;
        animation: fadeIn .8s ease-out;
    }
    .metric-card:hover { transform: translateY(-5px); box-shadow: 0 12px 48px rgba(240,147,251,.4); }
    @keyframes fadeIn { from { opacity:0; transform: scale(.9);} to { opacity:1; transform: scale(1);} }
    .metric-card h3 { font-size:1rem; margin:0 0 .5rem 0; opacity:.9; }
    .metric-card h2 { font-size:2rem; margin:0; font-weight:bold; }
    .quota-card {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        padding:1.5rem; border-radius:15px; color:white; box-shadow:0 8px 32px rgba(79,172,254,.3); margin-bottom:1rem;
    }
    .quota-number { font-size:3rem; font-weight:bold; margin:.5rem 0; }
    .status-box { padding:1.5rem; border-radius:15px; margin:1rem 0; animation: slideIn .5s ease-out; box-shadow:0 4px 20px rgba(0,0,0,.1); }
    @keyframes slideIn { from { opacity:0; transform: translateX(-20px);} to { opacity:1; transform: translateX(0);} }
    .status-success { background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); color:white; }
    .status-warning { background: linear-gradient(135deg, #f7971e 0%, #ffd200 100%); color:#333; }
    .status-error { background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%); color:white; }
    .status-info { background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); color:white; }
    .stButton>button {
        width:100%;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color:white; border:none; padding:1rem 2rem; font-size:1.1rem; font-weight:bold;
        border-radius:12px; box-shadow:0 6px 24px rgba(102,126,234,.3); transition: all .3s ease;
    }
    .stButton>button:hover { transform: translateY(-2px); box-shadow:0 8px 32px rgba(102,126,234,.4); }
    .stProgress > div > div { background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); }
    .loading-spinner {
        display:inline-block; width:20px; height:20px; border:3px solid rgba(255,255,255,.3);
        border-radius:50%; border-top-color:#fff; animation:spin 1s ease-in-out infinite;
    }
    @keyframes spin { to { transform: rotate(360deg); } }
    .badge {
        display:inline-block; padding:.5rem 1rem; border-radius:20px; font-size:.9rem; font-weight:bold; margin:.2rem;
    }
    .badge-success { background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); color:white; }
    .badge-warning { background: linear-gradient(135deg, #f7971e 0%, #ffd200 100%); color:#333; }
    .badge-error { background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%); color:white; }
    .file-display {
        padding:1rem; background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius:10px; margin:.5rem 0;
    }
    .file-display h4 { margin:0; color:#333; }
    .file-display p { margin:.5rem 0 0 0; color:#666; font-size:.9rem; }
    .qc-card {
        background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        padding: 1.5rem; border-radius: 15px; margin-bottom: 1rem;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .qc-card h4 { color: #333; margin: 0 0 0.5rem 0; }
    .qc-card p { color: #666; margin: 0.25rem 0; font-size: 0.9rem; }
</style>
""", unsafe_allow_html=True)


# API keys
API_KEYS = {
    "excel": "AIzaSyBzVNw34fbQRcxCSZDouR35hoZNxqsW6pc",
    "ocr": "AIzaSyCKoaSP6Wgj5FCJDGGXIBHy1rt61Cl2ZTs",
    "scrap": "AIzaSyAhuC9Grg_FlxwDwYUW-_CpNaFzjwUg24w"
}
for key_name, key_value in API_KEYS.items():
    os.environ[f"GOOGLE_API_KEY_{key_name.upper()}"] = key_value
    os.environ["GOOGLE_API_KEY"] = key_value
    os.environ["GEMINI_API_KEY"] = key_value


# GOOGLE SHEETS INTEGRATION
from google.oauth2 import service_account
from googleapiclient.discovery import build

GOOGLE_SCOPES = [
    'https://www.googleapis.com/auth/drive.file',
    'https://www.googleapis.com/auth/spreadsheets'
]

@st.cache_resource
def get_google_services():
    """connect to google drive and sheets"""
    try:
        creds = service_account.Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=GOOGLE_SCOPES
        )
        drive_service = build('drive', 'v3', credentials=creds)
        sheets_service = build('sheets', 'v4', credentials=creds)
        return drive_service, sheets_service
    except Exception as e:
        st.error(f"âŒ connection error to Google: {e}")
        return None, None

def _col_index_to_letter(col_index):
    """convert index to excel column letter"""
    result = ""
    while col_index >= 0:
        result = chr(col_index % 26 + 65) + result
        col_index = col_index // 26 - 1
    return result

def find_or_create_data_table(drive_service, sheets_service, folder_id=None):
    """find or create table in drive"""
    try:
        table_name = "Exhibition_Data_Table"
        query = f"name='{table_name}' and mimeType='application/vnd.google-apps.spreadsheet' and trashed=false"
        if folder_id:
            query += f" and '{folder_id}' in parents"
        
        results = drive_service.files().list(
            q=query, spaces='drive', fields='files(id, name, webViewLink)', pageSize=1
        ).execute()
        
        files = results.get('files', [])
        
        if files:
            file_id = files[0]['id']
            file_url = files[0].get('webViewLink', f"https://docs.google.com/spreadsheets/d/{file_id}/edit")
            print(f"   âœ… existing table: {file_id}")
            return file_id, file_url, True
        
        print(f"   ğŸ“ create new table...")
        spreadsheet = sheets_service.spreadsheets().create(
            body={
                'properties': {'title': table_name},
                'sheets': [{'properties': {'title': 'Data', 'gridProperties': {'frozenRowCount': 1}}}]
            },
            fields='spreadsheetId'
        ).execute()
        
        file_id = spreadsheet.get('spreadsheetId')
        file_url = f"https://docs.google.com/spreadsheets/d/{file_id}/edit"
        
        if folder_id:
            drive_service.files().update(fileId=file_id, addParents=folder_id, fields='id, parents').execute()
        
        print(f"   âœ… new table created: {file_id}")
        return file_id, file_url, False
        
    except Exception as e:
        print(f"   âŒ error: {e}")
        return None, None, False

def append_excel_data_to_sheets(excel_path, folder_id=None):
    """Read Excel data and append to Google Sheets (variable row count)"""
    try:
        drive_service, sheets_service = get_google_services()
        if not drive_service or not sheets_service:
            return False, "Google connection failed", None, 0

        print(f"\nâ˜ï¸ Starting data save to Google Drive...")

        # âœ… Use existing Google Sheet instead of creating a new one
        file_id = "1OeQbiqvo6v58rcxaoSUidOk0IxSGmL8YCpLnyh27yuE"
        file_url = f"https://docs.google.com/spreadsheets/d/{file_id}/edit"
        exists = True
        print(f"   âœ… Using existing Google Sheet: {file_url}")

        # file_id, file_url, exists = find_or_create_data_table(drive_service, sheets_service, folder_id)
        if not file_id:
            return False, "Error creating table", None, 0
        
        print(f"ğŸ“– Reading Excel data: {excel_path.name}")
        df = pd.read_excel(excel_path)
        if df.empty:
            return False, "Excel file is empty", None, 0
        
        print(f"   âœ… {len(df)} rows Ã— {len(df.columns)} columns read")
        
        # âœ… Clean DataFrame from NaN and None values
        df = df.replace({np.nan: "", None: ""})
        
        for col in df.columns:
            if df[col].dtype == 'object':
                df[col] = df[col].astype(str).replace('nan', '').replace('None', '').replace('NaT', '')
        
        sheet_name = 'Sheet1'
        
        result = sheets_service.spreadsheets().values().get(
            spreadsheetId=file_id, range=f'{sheet_name}!1:1'
        ).execute()
        
        existing_headers = result.get('values', [[]])[0] if result.get('values') else []
        new_headers = df.columns.tolist()
        
        print(f"   ğŸ“‹ Existing columns: {len(existing_headers)} | New columns: {len(new_headers)}")
        
        if not existing_headers:
            values = [new_headers] + df.values.tolist()
            print(f"   â„¹ï¸ Empty table, adding {len(new_headers)} columns")
        else:
            new_columns = [col for col in new_headers if col not in existing_headers]
            
            all_columns = existing_headers.copy()
            for col in new_columns:
                if col not in all_columns:
                    all_columns.append(col)
            
            print(f"   ğŸ“Š Final order: {len(all_columns)} columns")
            
            if new_columns:
                print(f"   ğŸ†• New columns: {new_columns}")
                print(f"   ğŸ”„ Updating headers...")
                sheets_service.spreadsheets().values().update(
                    spreadsheetId=file_id,
                    range=f'{sheet_name}!1:1',
                    valueInputOption='USER_ENTERED',
                    body={'values': [all_columns]}
                ).execute()
                
                result = sheets_service.spreadsheets().values().get(
                    spreadsheetId=file_id, range=f'{sheet_name}!A:A'
                ).execute()
                existing_rows_count = len(result.get('values', [])) - 1
                
                if existing_rows_count > 0:
                    print(f"   ğŸ“ Filling {existing_rows_count} old rows...")
                    empty_values = [[''] * len(new_columns) for _ in range(existing_rows_count)]
                    start_col_index = len(existing_headers)
                    start_col_letter = _col_index_to_letter(start_col_index)
                    end_col_letter = _col_index_to_letter(start_col_index + len(new_columns) - 1)
                    
                    sheets_service.spreadsheets().values().update(
                        spreadsheetId=file_id,
                        range=f'{sheet_name}!{start_col_letter}2:{end_col_letter}{existing_rows_count+1}',
                        valueInputOption='USER_ENTERED',
                        body={'values': empty_values}
                    ).execute()
                    print(f"   âœ… Old rows updated")
            
            for col in all_columns:
                if col not in df.columns:
                    df[col] = ''
            
            df = df[all_columns]
            print(f"   âœ… DataFrame sorted: {len(df)} rows Ã— {len(all_columns)} columns")
            values = df.values.tolist()

        # âœ… Convert all NaN or None to string before sending to Sheets
        values = [[("" if (pd.isna(cell) or cell is None) else str(cell)) for cell in row] for row in values]
        
        result = sheets_service.spreadsheets().values().get(
            spreadsheetId=file_id, range=f'{sheet_name}!A:A'
        ).execute()
        existing_rows = len(result.get('values', []))
        
        print(f"   ğŸ“Š Current rows: {existing_rows}")
        print(f"   ğŸ“¤ Adding {len(values)} rows...")
        
        body = {'values': values}
        result = sheets_service.spreadsheets().values().append(
            spreadsheetId=file_id,
            range=f'{sheet_name}!A:A',
            valueInputOption='USER_ENTERED',
            insertDataOption='INSERT_ROWS',
            body=body
        ).execute()
        
        updated_rows = result.get('updates', {}).get('updatedRows', 0)
        total_rows = existing_rows + updated_rows
        
        result = sheets_service.spreadsheets().values().get(
            spreadsheetId=file_id, range=f'{sheet_name}!1:1'
        ).execute()
        total_columns = len(result.get('values', [[]])[0])
        
        total_cells = total_rows * total_columns
        capacity = (total_cells / 10_000_000) * 100
        
        print(f"   âœ… {updated_rows} new rows added")
        print(f"   ğŸ“Š Total: {total_rows} rows Ã— {total_columns} columns")
        print(f"   ğŸ“Š Total cells: {total_cells:,} ({capacity:.1f}%)")
        print(f"   ğŸ”— {file_url}")
        
        message = f"âœ… {updated_rows} new rows | Total: {total_rows} rows | {total_columns} columns"
        return True, message, file_url, total_rows
        
    except Exception as e:
        print(f"   âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False, str(e), None, 0


def get_or_create_folder(folder_name="Exhibition_Data"):
    """find or create folder in drive"""
    try:
        drive_service, _ = get_google_services()
        if not drive_service:
            return None
        
        query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
        results = drive_service.files().list(
            q=query, spaces='drive', fields='files(id, name)', pageSize=1
        ).execute()
        files = results.get('files', [])
        
        if files:
            print(f"   âœ… existing folder: {files[0]['name']}")
            return files[0]['id']
        
        folder = drive_service.files().create(
            body={'name': folder_name, 'mimeType': 'application/vnd.google-apps.folder'},
            fields='id'
        ).execute()
        print(f"   âœ… existing folder: {folder_name}")
        return folder.get('id')
        
    except Exception as e:
        print(f"   âŒ error: {e}")
        return None


# Quota Management
DAILY_LIMIT = 240
QUOTA_FILE = Path("quota.json")

def save_quota(q):
    QUOTA_FILE.write_text(json.dumps(q, indent=2, ensure_ascii=False), encoding="utf-8")

def load_quota():
    today = datetime.date.today().isoformat()
    if QUOTA_FILE.exists():
        try:
            data = json.loads(QUOTA_FILE.read_text(encoding="utf-8"))
            file_date = data.get("date")
            if file_date != today:
                q = {"date": today, "used": 0, "remaining": DAILY_LIMIT}
                save_quota(q)
                return q
            used = data.get("used", 0)
            remaining = max(0, DAILY_LIMIT - used)
            q = {"date": today, "used": used, "remaining": remaining}
            save_quota(q)
            return q
        except Exception:
            pass
    q = {"date": today, "used": 0, "remaining": DAILY_LIMIT}
    save_quota(q)
    return q

def decrease_quota(amount=1):
    quota = load_quota()
    quota["used"] += amount
    quota["remaining"] = max(0, DAILY_LIMIT - quota["used"])
    save_quota(quota)
    return quota


# quality control tracking functions
def get_qc_metadata(user_name, user_role):
    """create quality control metadata"""
    now = datetime.datetime.now()
    return {
        "QC_Supervisor": user_name,
        "QC_Role": user_role,
        "QC_Date": now.strftime("%Y-%m-%d"),
        "QC_Time": now.strftime("%H:%M:%S"),
        "QC_Timestamp": now.strftime("%Y-%m-%d %H:%M:%S")
    }

def add_qc_metadata_to_excel(excel_path, qc_metadata):
    """add quality control metadata to excel"""
    try:
        df = pd.read_excel(excel_path)
        for key in ["QC_Supervisor", "QC_Role", "QC_Date", "QC_Time", "QC_Timestamp"]:
            if key in qc_metadata:
                df.insert(0, key, qc_metadata[key])
        df.to_excel(excel_path, index=False, engine='openpyxl')
        print(f"   âœ… QC Metadata added: {qc_metadata['QC_Supervisor']} ({qc_metadata['QC_Role']})")
        return True
    except Exception as e:
        print(f"   âŒ Error adding QC metadata: {e}")
        return False

def save_qc_log(session_dir, qc_metadata, exhibition_name, pipeline_type, total_files):
    """save the quality control log to a json file"""
    try:
        qc_log_file = session_dir / "qc_log.json"
        qc_log = {
            **qc_metadata,
            "Exhibition": exhibition_name,
            "Pipeline_Type": pipeline_type,
            "Total_Files": total_files,
            "Session_Dir": str(session_dir)
        }
        qc_log_file.write_text(json.dumps(qc_log, indent=2, ensure_ascii=False), encoding="utf-8")
        print(f"   âœ… QC Log saved: {qc_log_file}")
        return True
    except Exception as e:
        print(f"   âŒ Error saving QC log: {e}")
        return False


# share smart functions
def detect_source_type(file_name):
    if not file_name or pd.isna(file_name):
        return "Unknown"
    file_name = str(file_name).lower()
    if file_name.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.webp', '.gif')):
        return "Image"
    elif file_name.endswith('.pdf'):
        return "PDF"
    elif file_name.endswith(('.xlsx', '.xls', '.csv')):
        return "Excel"
    else:
        return "Unknown"

def smart_position_from_department(department):
    if not department or pd.isna(department) or str(department).strip() == '':
        return None
    department = str(department).strip().lower()
    department_position_map = {
        'sales': 'sales manager',
        'marketing': 'marketing manager',
        'export': 'export manager',
        'import': 'import manager',
        'commerce': 'commerce manager',
        'management': 'chief executive officer',
        'executive': 'executive manager',
        'ceo': 'chief executive officer',
        'production': 'production manager',
        'factory': 'factory manager',
        'operations': 'operations manager',
        'technical': 'technical manager',
        'finance': 'financial manager',
        'accounting': 'accounting manager',
        'hr': 'human resources manager',
        'it': 'it manager',
        'r&d': 'r&d manager',
        'qc': 'quality control manager',
        'support': 'support manager',
        'logistics': 'logistics manager',
        'warehouse': 'warehouse manager',
        'purchasing': 'purchasing manager',
        'pr': 'public relations manager',
        }
    for key, position in department_position_map.items():
        if key in department:
            return position
    if any(word in department for word in [ 'manager', 'chief']):
        return f"manager {department.title()}"
    elif any(word in department for word in [ 'deputy']):
        return f"deputy {department.title()}"
    elif any(word in department for word in [ 'expert']):
        return f"expert {department.title()}"
    return f"officer {department.title()}"

def add_exhibition_and_source(excel_path, exhibition_name):
    """UI"""
    try:
        print(f"\nğŸ“ Adding Exhibition & Source metadata...")
        df = pd.read_excel(excel_path)
        print(f"   âœ“ Loaded: {len(df)} rows Ã— {len(df.columns)} columns")

        df.insert(0, 'Exhibition', exhibition_name)
        if 'file_name' in df.columns:
            df.insert(1, 'Source', df['file_name'].apply(detect_source_type))
        elif 'url' in df.columns or 'Website' in df.columns:
            df.insert(1, 'Source', 'Excel')
        else:
            df.insert(1, 'Source', 'Unknown')

        if 'Department' in df.columns and 'PositionFA' in df.columns:
            print(f"\nğŸ¤– Smart Position Detection...")
            filled_count = 0
            for idx in df.index:
                if pd.isna(df.loc[idx, 'PositionFA']) or str(df.loc[idx, 'PositionFA']).strip() == '':
                    department = df.loc[idx, 'Department']
                    smart_position = smart_position_from_department(department)
                    if smart_position:
                        df.loc[idx, 'PositionFA'] = smart_position
                        filled_count += 1
                        print(f"   âœ“ Row {idx + 1}: {department} â†’ {smart_position}")
            if filled_count > 0:
                st.info(f"ğŸ¤– filled {filled_count} role based on department")

        columns_to_remove = ['CompanyNameFA_translated']
        removed = 0
        for col in columns_to_remove:
            if col in df.columns:
                df.drop(col, axis=1, inplace=True)
                removed += 1
                print(f"   ğŸ—‘ï¸ Removed column: {col}")
        if removed:
            print(f"   âœ… Removed {removed} unnecessary columns")

        for col in df.columns:
            if df[col].dtype == 'object':
                try:
                    df[col] = df[col].astype(str)
                    df[col] = df[col].replace('nan', None).replace('', None)
                except Exception as e:
                    print(f"   âš ï¸ Warning: Could not convert column {col}: {e}")

        df.to_excel(excel_path, index=False, engine='openpyxl')
        print(f"   âœ… Updated: {excel_path}")
        print(f"   ğŸ“Š Final: {len(df)} rows Ã— {len(df.columns)} columns")
        return True
    except Exception as e:
        print(f"   âŒ Error adding metadata: {e}")
        st.error(f"error adding metadata: {e}")
        return False


# detect pipeline type and exhibition name
def detect_pipeline_type(files):
    extensions = [f.name.split('.')[-1].lower() for f in files]
    if any(ext in ['xlsx', 'xls'] for ext in extensions):
        return 'excel'
    elif any(ext in ['pdf', 'jpg', 'jpeg', 'png'] for ext in extensions):
        return 'ocr_qr'
    return None

def extract_exhibition_name(files):
    if not files:
        return "Unknown_Exhibition"
    first_file = files[0].name
    name_without_ext = first_file.rsplit('.', 1)[0]
    name_parts = re.split(r'[_\-\s]+', name_without_ext)
    cleaned_parts = [p for p in name_parts if not p.isdigit() and len(p) > 2]
    if cleaned_parts:
        return " ".join(cleaned_parts[:3])
    return "Unknown_Exhibition"


# Batch Processing Logic
def get_batch_size(file_type):
    """set batch size based on file type"""
    file_type = file_type.lower()
    if file_type in ['jpg', 'jpeg', 'png', 'bmp', 'webp', 'gif']:
        return 5
    elif file_type == 'pdf':
        return 4
    elif file_type in ['xlsx', 'xls']:
        return 1
    else:
        return 1

def create_batches(files_list, batch_size):
    """split file list into smaller batches"""
    batches = []
    for i in range(0, len(files_list), batch_size):
        batches.append(files_list[i:i + batch_size])
    return batches

def process_files_in_batches(uploads_dir, pipeline_type):
    """process files in batches"""
    if pipeline_type == 'excel':
        excel_files = list(uploads_dir.glob("*.xlsx")) + list(uploads_dir.glob("*.xls"))
        return [(f,) for f in excel_files], 1
    
    elif pipeline_type == 'ocr_qr':
        image_files = []
        pdf_files = []
        
        for f in uploads_dir.iterdir():
            if f.is_file():
                ext = f.suffix.lower()
                if ext in ['.jpg', '.jpeg', '.png', '.bmp', '.webp', '.gif']:
                    image_files.append(f)
                elif ext == '.pdf':
                    pdf_files.append(f)
        
        image_batches = create_batches(image_files, 5) if image_files else []
        pdf_batches = create_batches(pdf_files, 4) if pdf_files else []
        all_batches = image_batches + pdf_batches
        
        if image_files and pdf_files:
            avg_batch_size = (5 + 4) / 2
        elif image_files:
            avg_batch_size = 5
        elif pdf_files:
            avg_batch_size = 4
        else:
            avg_batch_size = 1
        
        return all_batches, int(avg_batch_size)
    
    return [], 1


# Fast Mode + Log File
def run_script(script_name, session_dir, log_area, status_text, script_display_name="", fast_mode=True):
    script_path = Path(script_name)
    if not script_display_name:
        script_display_name = script_name
    if not script_path.exists():
        script_path = Path.cwd() / script_name
        if not script_path.exists():
            status_text.markdown(f"""
            <div class="status-box status-error">âŒ file {script_name} not found! </div>
            """, unsafe_allow_html=True)
            return False

    status_text.markdown(f"""
    <div class="status-box status-info">
        <div class="loading-spinner"></div> running {script_display_name}...
    </div>
    """, unsafe_allow_html=True)

    logs_dir = session_dir / "logs"
    logs_dir.mkdir(exist_ok=True)
    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = logs_dir / f"log_{script_path.stem}_{timestamp}.txt"

    env = os.environ.copy()
    env["SESSION_DIR"] = str(session_dir)
    env["SOURCE_FOLDER"] = str(session_dir / "uploads")

    try:
        with subprocess.Popen(
            [sys.executable, str(script_path)],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            cwd=Path.cwd(),
            env=env,
            text=True,
            bufsize=1
        ) as process:
            all_output = ""
            line_count = 0
            with open(log_file, "w", encoding="utf-8") as log_f:
                for line in process.stdout:
                    all_output += line
                    log_f.write(line)
                    log_f.flush()
                    line_count += 1
                    if fast_mode:
                        if line_count % 10 == 0:
                            log_area.code(all_output[-2000:], language="bash")
                    else:
                        log_area.code(all_output[-3000:], language="bash")
                        time.sleep(0.05)
            process.wait()

        if process.returncode == 0:
            status_text.markdown(f"""
            <div class="status-box status-success">âœ… {script_display_name} successful!</div>
            """, unsafe_allow_html=True)
            return True
        else:
            status_text.markdown(f"""
            <div class="status-box status-warning">âš ï¸ {script_display_name} encountered an error(exit code: {process.returncode})</div>
            """, unsafe_allow_html=True)
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        st.code(''.join(lines[-50:]), language='bash')
            except:
                pass
            return False

    except Exception as e:
        status_text.markdown(f"""
        <div class="status-box status-error">âŒ running error: {str(e)}</div>
        """, unsafe_allow_html=True)
        return False


# Header
st.markdown("""
<div class="main-header">
    <h1>ğŸ¯ Smart Exhibition Pipeline</h1>
    <p>smart detection â€¢ automated processing â€¢ unified outputâ€¢ Batch Processing â€¢ Quality Control â€¢ Google Sheets</p>
</div>
""", unsafe_allow_html=True)


# Sidebar
# ========== link to Google Sheets ==========
if 'sheet_url' in st.session_state:
    st.sidebar.markdown(f"""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
        <h4 style="color: white; margin: 0 0 0.5rem 0;">ğŸ“Š data table</h4>
        <a href="{st.session_state['sheet_url']}" target="_blank" 
           style="color: white; background: rgba(255,255,255,0.2); 
                  padding: 0.5rem 1rem; border-radius: 8px; 
                  text-decoration: none; display: block; text-align: center;">
            ğŸ”— open table
        </a>
    </div>
    """, unsafe_allow_html=True)
elif Path("google_sheet_link.txt").exists():
    try:
        saved_link = Path("google_sheet_link.txt").read_text(encoding='utf-8')
        url_line = [line for line in saved_link.split('\n') if line.startswith('https://')]
        if url_line:
            saved_url = url_line[0]
            st.sidebar.markdown(f"""
            <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                        padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
                <h4 style="color: white; margin: 0 0 0.5rem 0;">ğŸ“Š data table</h4>
                <a href="{saved_url}" target="_blank" 
                   style="color: white; background: rgba(255,255,255,0.2); 
                          padding: 0.5rem 1rem; border-radius: 8px; 
                          text-decoration: none; display: block; text-align: center;">
                    ğŸ”—  open table
                </a>
                <p style="color: rgba(255,255,255,0.8); font-size: 0.85rem; margin: 0.5rem 0 0 0;">
                    saved link
                </p>
            </div>
            """, unsafe_allow_html=True)
    except:
        pass
# ========== quick link end ==========

quota = load_quota()
st.sidebar.markdown(f"""
<div class="quota-card">
    <h3>ğŸ“Š API Quota today</h3>
    <div class="quota-number">{quota['remaining']}</div>
    <p>Ø§Ø² {DAILY_LIMIT} request</p>
</div>
""", unsafe_allow_html=True)
progress_value = quota['used'] / DAILY_LIMIT if DAILY_LIMIT > 0 else 0
st.sidebar.progress(progress_value)

if quota['remaining'] <= 0:
    st.sidebar.markdown('<span class="badge badge-error">âŒ quota exceeded</span>', unsafe_allow_html=True)
elif quota['remaining'] < 20:
    st.sidebar.markdown('<span class="badge badge-warning">âš ï¸ reduced</span>', unsafe_allow_html=True)
else:
    st.sidebar.markdown('<span class="badge badge-success">âœ… good quota</span>', unsafe_allow_html=True)

st.sidebar.markdown("---")
st.sidebar.markdown("### âš™ï¸ setting")
rate_limit = st.sidebar.slider("â±ï¸ request interval (seconds)", 0, 10, 4)
if rate_limit < 4:
    st.sidebar.markdown('<span class="badge badge-error">âš ï¸ error Block</span>', unsafe_allow_html=True)
elif rate_limit == 4:
    st.sidebar.markdown('<span class="badge badge-success">âœ… safe (15 RPM)</span>', unsafe_allow_html=True)
else:
    st.sidebar.markdown('<span class="badge badge-success">ğŸ”’ very secure</span>', unsafe_allow_html=True)

debug_mode = st.sidebar.checkbox("ğŸ› Debug Mode")
fast_mode = st.sidebar.checkbox("âš¡ï¸ Fast Mode", value=True)

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ”‘ key status")
for key_name, key_value in API_KEYS.items():
    st.sidebar.text(f"{key_name.upper()}: {key_value[:20]}...")

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“¦ Batch Processing")
st.sidebar.info("ğŸ“¸ Image: 5 \nğŸ“„ PDF: 4 \nğŸ“Š Excel: 1 ")



# upload files
st.markdown("## upload files")
uploaded_files = st.file_uploader(
    "drag or click to upload your files",
    type=['xlsx', 'xls', 'pdf', 'jpg', 'jpeg', 'png'],
    accept_multiple_files=True,
    help="Excel â†’ Excel Mode | Image/PDF â†’ OCR/QR Pipeline"
)


# Quality Control Section
st.markdown("## ğŸ‘¤ quality supervisor information")
st.markdown("*this information is recorded as quality control metadata in the output*")

col_qc1, col_qc2 = st.columns(2)
with col_qc1:
    qc_user_name = st.text_input(
        "ğŸ§‘â€ğŸ’¼ full name",
        placeholder="example: Tara Gearo",
        help="full name of data quality supervisor"
    )
with col_qc2:
    qc_user_role = st.text_input(
        "ğŸ’¼ role / position",
        placeholder="example: quality control specialist",
        help="your role or position in the organization"
    )

if qc_user_name and qc_user_role:
    qc_preview = get_qc_metadata(qc_user_name, qc_user_role)
    st.markdown(f"""
    <div class="qc-card">
        <h4>âœ… quality control information preview</h4>
        <p><strong>ğŸ‘¤ supervisor:</strong> {qc_preview['QC_Supervisor']}</p>
        <p><strong>ğŸ’¼ position:</strong> {qc_preview['QC_Role']}</p>
        <p><strong>ğŸ“… date:</strong> {qc_preview['QC_Date']}</p>
        <p><strong>ğŸ• time:</strong> {qc_preview['QC_Time']}</p>
    </div>
    """, unsafe_allow_html=True)

st.markdown("---")

if uploaded_files:
    pipeline_type = detect_pipeline_type(uploaded_files)
    exhibition_name = extract_exhibition_name(uploaded_files)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h3>ğŸ” type Pipeline</h3>
            <h2>{'ğŸ“Š Excel' if pipeline_type == 'excel' else 'ğŸ–¼ OCR/QR'}</h2>
        </div>
        """, unsafe_allow_html=True)
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <h3>ğŸ“ number of files</h3>
            <h2>{len(uploaded_files)}</h2>
        </div>
        """, unsafe_allow_html=True)
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <h3>ğŸ¢ exhibition</h3>
            <h2>{exhibition_name[:15]}</h2>
        </div>
        """, unsafe_allow_html=True)

    exhibition_name = st.text_input(
        "ğŸ“ edit exhibition name",
        value=exhibition_name,
        help="recorded in the exhibition column"
    )

    session_timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    session_dir = Path(f"session_{session_timestamp}")
    uploads_dir = session_dir / "uploads"
    logs_dir = session_dir / "logs"
    uploads_dir.mkdir(parents=True, exist_ok=True)
    logs_dir.mkdir(parents=True, exist_ok=True)

    for f in uploaded_files:
        (uploads_dir / f.name).write_bytes(f.getbuffer())

    os.environ["SESSION_DIR"] = str(session_dir)
    os.environ["SOURCE_FOLDER"] = str(uploads_dir)
    os.environ["EXHIBITION_NAME"] = exhibition_name

    if pipeline_type == 'excel':
        excel_files = list(uploads_dir.glob("*.xlsx")) + list(uploads_dir.glob("*.xls"))
        if excel_files:
            os.environ["INPUT_EXCEL"] = str(excel_files[0])

    batches, batch_size = process_files_in_batches(uploads_dir, pipeline_type)
    total_batches = len(batches)
    
    if total_batches > 0:
        st.info(f"ğŸ“¦  Batchâ€Œ number: {total_batches} | Batch size: {batch_size}")

    st.markdown("---")

    if st.button("ğŸš€ start processing", type="primary"):
        if not qc_user_name or not qc_user_role:
            st.markdown("""
            <div class="status-box status-warning">
                âš ï¸ please enter the quality supervisor information (name and role)!
            </div>
            """, unsafe_allow_html=True)
            st.stop()
        
        if quota['remaining'] <= 0:
            st.markdown("""
            <div class="status-box status-error">âŒ API quota exceeded! please try again tomorrow.</div>
            """, unsafe_allow_html=True)
            st.stop()

        qc_metadata = get_qc_metadata(qc_user_name, qc_user_role)
        save_qc_log(session_dir, qc_metadata, exhibition_name, pipeline_type, len(uploaded_files))
        
        st.markdown("## ğŸ”„processing in progress...")
        progress_bar = st.progress(0)
        status_text = st.empty()
        log_area = st.empty()
        quota_display = st.empty()

        start_time = time.time()
        success = False
        output_files = []

        try:
            if pipeline_type == 'excel':
                st.markdown("""
                <div class="status-box status-info">ğŸ“Š Excel Mode activated</div>
                """, unsafe_allow_html=True)

                excel_input = os.environ.get("INPUT_EXCEL")
                if not excel_input or not Path(excel_input).exists():
                    st.markdown("""
                    <div class="status-box status-error">âŒ  Excel file not found</div>
                    """, unsafe_allow_html=True)
                    st.stop()

                try:
                    df_input = pd.read_excel(excel_input)
                    total_rows = len(df_input)
                    st.info(f"ğŸ“Š number of companies: {total_rows}")
                    current_quota = load_quota()
                    if current_quota['remaining'] < total_rows:
                        st.warning(f"âš ï¸insufficient quota! required: {total_rows}, Ù…ÙˆØ¬ÙˆØ¯: {current_quota['remaining']}")
                        if not st.checkbox("continue with insufficient quota?"):
                            st.stop()
                except Exception as e:
                    st.warning(f"could not read row count: {e}")
                    total_rows = 0

                progress_bar.progress(10)
                current_quota = load_quota()
                quota_display.info(f"ğŸ”‹ remaining quota: {current_quota['remaining']}/{DAILY_LIMIT}")

                st.info(f"ğŸ“¦ process rows {total_rows} in Batch (size: 1)")
                
                success = run_script(
                    "excel_mode.py",
                    session_dir,
                    log_area,
                    status_text,
                    "ğŸ“Š Excel Web Scraper",
                    fast_mode
                )
                progress_bar.progress(100)

                if total_rows > 0:
                    quota = decrease_quota(total_rows)
                    quota_display.success(f"âœ… remaining quota: {quota['remaining']}/{DAILY_LIMIT} (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡: {total_rows})")
                else:
                    quota = decrease_quota(1)
                    quota_display.success(f"âœ… remaining quota: {quota['remaining']}/{DAILY_LIMIT}")

                output_files = list(session_dir.glob("output_enriched_*.xlsx"))
                if not output_files:
                    output_files = [f for f in session_dir.glob("**/*.xlsx")
                                    if "output" in f.name.lower() or "enriched" in f.name.lower()]

            else:
                st.markdown("""
                <div class="status-box status-info">ğŸ–¼ OCR/QR Pipeline ÙØ¹Ø§Ù„ Ø´Ø¯</div>
                """, unsafe_allow_html=True)

                if total_batches > 0:
                    st.info(f"ğŸ“¦ Ù¾Ø±Ø¯Ø§Ø²Ø´ {total_batches} Batch | Ù‡Ø± Batch Ø­Ø¯ÙˆØ¯ {batch_size} ÙØ§ÛŒÙ„")

                stages = [
                    ("ğŸ“˜ OCR Extraction", "ocr_dyn.py", 20),
                    ("ğŸ” QR Detection", "qr_dyn.py", 40),
                    ("ğŸ§© Merge OCR+QR", "mix_ocr_qr_dyn.py", 60),
                    ("ğŸŒ Web Scraping", "scrap.py", 80),
                    ("ğŸ’  Final Merge", "final_mix.py", 100)
                ]

                all_success = True
                for stage_name, script, progress_val in stages:
                    current_quota = load_quota()
                    quota_display.info(f"ğŸ”‹ Ø³Ù‡Ù…ÛŒÙ‡ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: {current_quota['remaining']}/{DAILY_LIMIT}")

                    if total_batches > 0:
                        st.markdown(f"**{stage_name}** - Ù¾Ø±Ø¯Ø§Ø²Ø´ {total_batches} Batch...")

                    stage_success = run_script(
                        script, session_dir, log_area, status_text,
                        stage_name, fast_mode
                    )
                    if not stage_success:
                        all_success = False
                        st.markdown(f"""
                        <div class="status-box status-warning">âš ï¸ {stage_name} Ø¨Ø§ Ù…Ø´Ú©Ù„ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ØŒ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…...</div>
                        """, unsafe_allow_html=True)

                    progress_bar.progress(progress_val)
                    time.sleep(rate_limit)
                    
                    quota_decrease_amount = max(1, total_batches)
                    quota = decrease_quota(quota_decrease_amount)
                    quota_display.success(f"âœ… Ø³Ù‡Ù…ÛŒÙ‡ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: {quota['remaining']}/{DAILY_LIMIT}")
                    
                    if quota['remaining'] <= 0:
                        st.markdown('<div class="status-box status-error">âŒ Ø³Ù‡Ù…ÛŒÙ‡ API ØªÙ…Ø§Ù… Ø´Ø¯!</div>', unsafe_allow_html=True)
                        break

                success = all_success
                output_files = list(session_dir.glob("merged_final_*.xlsx"))
                if not output_files:
                    output_files = [f for f in session_dir.glob("**/*.xlsx")
                                    if any(kw in f.name.lower() for kw in ["merged", "final", "output"])]

            elapsed = time.time() - start_time

            if success and output_files:
                st.info("ğŸ“ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ExhibitionØŒ Source Ùˆ QC Metadata...")
                for output_file in output_files:
                    add_exhibition_and_source(output_file, exhibition_name)
                    add_qc_metadata_to_excel(output_file, qc_metadata)
                
                # ========== GOOGLE SHEETS UPLOAD ==========
                st.markdown("---")
                st.markdown("## â˜ï¸ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Google Drive")
                st.info("ğŸ’¡ ÙÙ‚Ø· Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ Excel Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ù†Ù‡ Ø®ÙˆØ¯ ÙØ§ÛŒÙ„!")
                
                sheets_status = st.empty()
                sheets_status.info("ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
                
                try:
                    folder_id = get_or_create_folder("Exhibition_Data")
                    
                    for output_file in output_files:
                        success_gs, msg_gs, url_gs, total_rows = append_excel_data_to_sheets(
                            excel_path=output_file,
                            folder_id=folder_id
                        )
                        
                        if success_gs:
                            sheets_status.markdown(f"""
                            <div class="status-box status-success">
                                {msg_gs}
                            </div>
                            """, unsafe_allow_html=True)
                            
                            st.session_state['sheet_url'] = url_gs
                            st.session_state['sheet_id'] = url_gs.split('/d/')[1].split('/')[0] if '/d/' in url_gs else ''
                            
                            link_file = Path("google_sheet_link.txt")
                            link_file.write_text(f"Ù„ÛŒÙ†Ú© Ø¬Ø¯ÙˆÙ„:\n{url_gs}", encoding='utf-8')
                            
                            total_cells = total_rows * 90
                            capacity = (total_cells / 10_000_000) * 100
                            
                            col_a, col_b, col_c = st.columns(3)
                            with col_a:
                                st.metric("ğŸ“Š Ú©Ù„ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§", f"{total_rows:,}")
                            with col_b:
                                st.metric("ğŸ“¦ Ú©Ù„ Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§", f"{total_cells:,}")
                            with col_c:
                                st.metric("âš¡ï¸ Ø¸Ø±ÙÛŒØª", f"{capacity:.1f}%")
                            
                            st.markdown(f"""
                            <div class="file-display" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                                <h4>ğŸ”— Ù„ÛŒÙ†Ú© Ø¯Ø§Ø¦Ù…ÛŒ Ø¬Ø¯ÙˆÙ„</h4>
                                <p style="background: rgba(255,255,255,0.2); padding: 1rem; border-radius: 8px; margin: 0.5rem 0;">
                                    <a href="{url_gs}" target="_blank" style="color: white; font-weight: bold; font-size: 1.1rem;">
                                        ğŸ“Š Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Ø¯Ø± Google Drive
                                    </a>
                                </p>
                                <p style="font-size: 0.9rem; margin: 0.5rem 0 0 0; opacity: 0.9;">
                                    ğŸ’¡ Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© Ù‡Ù…ÛŒØ´Ù‡ Ø«Ø§Ø¨Øª Ø§Ø³Øª! Bookmark Ú©Ù†ÛŒØ¯!
                                </p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            st.code(url_gs, language=None)
                            
                            if capacity > 80:
                                st.warning(f"âš ï¸ Ø¸Ø±ÙÛŒØª Ø¨Ø§Ù„Ø§ ({capacity:.1f}%)!")
                            else:
                                st.success(f"âœ… ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ ({100-capacity:.1f}% Ø¨Ø§Ù‚ÛŒ)")
                        else:
                            sheets_status.error(f"âŒ Ø®Ø·Ø§: {msg_gs}")
                
                except Exception as e:
                    sheets_status.error(f"âŒ Ø®Ø·Ø§: {e}")
                    st.warning("ğŸ’¡ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Google Drive API Ùˆ Sheets API ÙØ¹Ø§Ù„ Ø§Ø³Øª")
                # ========== END GOOGLE SHEETS ==========

            st.markdown("---")

            if success and output_files:
                st.markdown("""
                <div class="status-box status-success">
                    <h2>ğŸ‰ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ù…Ù„ Ø´Ø¯!</h2>
                </div>
                """, unsafe_allow_html=True)

                st.markdown(f"""
                <div class="qc-card">
                    <h4>ğŸ‘¤ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø§Ø¸Ø± Ú©ÛŒÙÛŒØª</h4>
                    <p><strong>Ù†Ø§Ø¸Ø±:</strong> {qc_metadata['QC_Supervisor']} | <strong>Ù†Ù‚Ø´:</strong> {qc_metadata['QC_Role']}</p>
                    <p><strong>ØªØ§Ø±ÛŒØ® Ùˆ Ø³Ø§Ø¹Øª:</strong> {qc_metadata['QC_Timestamp']}</p>
                </div>
                """, unsafe_allow_html=True)

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>â±ï¸ Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§</h3>
                        <h2>{elapsed:.1f}s</h2>
                    </div>
                    """, unsafe_allow_html=True)
                with col2:
                    quota_now = load_quota()
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>ğŸ”‹ Ø³Ù‡Ù…ÛŒÙ‡ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡</h3>
                        <h2>{quota_now['remaining']}</h2>
                    </div>
                    """, unsafe_allow_html=True)
                with col3:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>ğŸ“Š ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ</h3>
                        <h2>{len(output_files)}</h2>
                    </div>
                    """, unsafe_allow_html=True)

                st.markdown("## ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ")
                for output_file in output_files:
                    with st.container():
                        colA, colB = st.columns([3, 1])
                        with colA:
                            st.markdown(f"""
                            <div class="file-display">
                                <h4>ğŸ“„ {output_file.name}</h4>
                                <p>Ø­Ø¬Ù…: {output_file.stat().st_size / 1024:.1f} KB</p>
                            </div>
                            """, unsafe_allow_html=True)
                        with colB:
                            with open(output_file, "rb") as f:
                                st.download_button(
                                    label="â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯",
                                    data=f,
                                    file_name=output_file.name,
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    key=f"download_{output_file.name}"
                                )
                        try:
                            df_prev = pd.read_excel(output_file)
                            for c in df_prev.columns:
                                if df_prev[c].dtype == 'object':
                                    df_prev[c] = df_prev[c].astype(str).replace('nan', '')
                            with st.expander(f"ğŸ‘ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ {output_file.name}"):
                                st.markdown(f"""
                                <div class="status-box status-info" style="margin-top:0;">
                                    <p style="margin:0;">ğŸ“Š <strong>{len(df_prev)}</strong> Ø±Ø¯ÛŒÙ Ã— 
                                       <strong>{len(df_prev.columns)}</strong> Ø³ØªÙˆÙ†</p>
                                </div>
                                """, unsafe_allow_html=True)
                                cols_display = ", ".join(df_prev.columns.tolist()[:20])
                                if len(df_prev.columns) > 20: cols_display += "..."
                                st.info(f"ğŸ”¤ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: {cols_display}")
                                st.dataframe(df_prev.head(10), width='stretch')
                        except Exception as e:
                            st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´: {e}")

                json_files = [f for f in session_dir.glob("*.json") if f.name != "quota.json"]
                if json_files:
                    with st.expander("ğŸ“„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ùˆ Ù„Ø§Ú¯â€ŒÙ‡Ø§ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)"):
                        for json_file in json_files:
                            col1, col2 = st.columns([3, 1])
                            with col1:
                                if json_file.name == "qc_log.json":
                                    st.write(f"**ğŸ‘¤ {json_file.name}** (Ù„Ø§Ú¯ Ú©Ù†ØªØ±Ù„ Ú©ÛŒÙÛŒØª)")
                                else:
                                    st.write(f"**{json_file.name}**")
                            with col2:
                                with open(json_file, "rb") as f:
                                    st.download_button(
                                        label="â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯",
                                        data=f,
                                        file_name=json_file.name,
                                        mime="application/json",
                                        key=f"download_json_{json_file.name}"
                                    )
                st.balloons()

            else:
                st.markdown("""
                <div class="status-box status-warning">
                    <h2>âš ï¸ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ù†Ø´Ø¯</h2>
                    <p>Ø¨Ø¹Ø¶ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø´Ø¯Ù†Ø¯. Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.</p>
                </div>
                """, unsafe_allow_html=True)
                st.info("ğŸ’¡ Ù†Ú©ØªÙ‡: Ø§Ú¯Ø± Ø´Ø±Ú©ØªÛŒ URL Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ù† Ø±Ø§ Ø§Ø² ÙˆØ¨ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯.")
                if debug_mode:
                    with st.expander("ğŸ” Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Session"):
                        for f in session_dir.rglob("*"):
                            if f.is_file():
                                st.write(f"ğŸ“„ {f.relative_to(session_dir)}")

        except Exception as e:
            st.markdown("""
            <div class="status-box status-error">
                <h2>âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡</h2>
            </div>
            """, unsafe_allow_html=True)
            st.error(f"Ø®Ø·Ø§: {str(e)}")
            if debug_mode:
                import traceback
                with st.expander("ğŸ“‹ Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§"):
                    st.code(traceback.format_exc())

else:
    st.markdown("""
    <div class="status-box status-info">
        <h3>ğŸ‘‹ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!</h3>
        <p>Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø§Ø¸Ø± Ú©ÛŒÙÛŒØª Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ØŒ Ø³Ù¾Ø³ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯</p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    padding: 2rem; border-radius: 15px; color: white; height: 100%;">
            <h3>ğŸ“Š Excel Mode</h3>
            <ul style="line-height: 2;">
                <li>ÙØ§ÛŒÙ„ Excel Ø¨Ø§ URL/Website</li>
                <li>ÙˆØ¨â€ŒØ§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ù‡ÙˆØ´Ù…Ù†Ø¯</li>
                <li>Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù…Ù„ Ø´Ø±Ú©Øª</li>
                <li>Ø®Ø±ÙˆØ¬ÛŒ: Excel ØºÙ†ÛŒâ€ŒØ´Ø¯Ù‡</li>
                <li>ğŸ“¦ Batch: 1 Ø±Ø¯ÛŒÙ</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    with col2:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); 
                    padding: 2rem; border-radius: 15px; color: white; height: 100%;">
            <h3>ğŸ–¼ OCR/QR Mode</h3>
            <ul style="line-height: 2;">
                <li>ØªØµØ§ÙˆÛŒØ± (JPG, PNG) ÛŒØ§ PDF</li>
                <li>Ø§Ø³ØªØ®Ø±Ø§Ø¬ OCR + ØªØ´Ø®ÛŒØµ QR</li>
                <li>ÙˆØ¨â€ŒØ§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ø§Ø² URLÙ‡Ø§</li>
                <li>Ø®Ø±ÙˆØ¬ÛŒ: Excel ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡</li>
                <li>ğŸ“¦ Batch: ØªØµØ§ÙˆÛŒØ±(5) | PDF(4)</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")
    st.markdown("### âœ¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ")
    features = [
        ("ğŸ¯", "ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø±", "Excel ÛŒØ§ OCR/QR Ø¨Ù‡ ØµÙˆØ±Øª Ù‡ÙˆØ´Ù…Ù†Ø¯"),
        ("ğŸ¢", "Exhibition Field", "Ù†Ø§Ù… Ù†Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ Ù‚Ø§Ø¨Ù„ ÙˆÛŒØ±Ø§ÛŒØ´"),
        ("ğŸ“Š", "Source Tracking", "ØªØ´Ø®ÛŒØµ Ù…Ù†Ø¨Ø¹ (Image/PDF/Excel)"),
        ("ğŸ¤–", "Smart Position", "50+ Ø¯Ù¾Ø§Ø±ØªÙ…Ø§Ù† ÙØ§Ø±Ø³ÛŒ/Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ"),
        ("ğŸ”‹", "Quota Management", "Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ÙˆØ´Ù…Ù†Ø¯ API (240/Ø±ÙˆØ²)"),
        ("âš¡ï¸", "Fast Mode", "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹ Ø¨Ø§ Ù„Ø§Ú¯ Ø¨Ù‡ÛŒÙ†Ù‡"),
        ("ğŸ”’", "Rate Limit", "4 Ø«Ø§Ù†ÛŒÙ‡ (Ø§ÛŒÙ…Ù† - 15 RPM)"),
        ("ğŸ“¦", "Batch Processing", "ØªØµØ§ÙˆÛŒØ±(5) | PDF(4) | Excel(1)"),
        ("ğŸ‘¤", "Quality Control", "Ø«Ø¨Øª Ù†Ø§Ù… Ùˆ Ù†Ù‚Ø´ Ù†Ø§Ø¸Ø± Ú©ÛŒÙÛŒØª"),
        ("â˜ï¸", "Google Sheets", "Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø± Drive")
    ]
    cols = st.columns(3)
    for idx, (icon, title, desc) in enumerate(features):
        with cols[idx % 3]:
            st.markdown(f"""
            <div style="text-align: center; padding: 1rem; background: white; 
                        border-radius: 10px; margin: 0.5rem 0; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                <div style="font-size: 2rem;">{icon}</div>
                <h4 style="margin: 0.5rem 0; color: #667eea;">{title}</h4>
                <p style="margin: 0; font-size: 0.85rem; color: #666;">{desc}</p>
            </div>
            """, unsafe_allow_html=True)

st.markdown("---")
st.markdown("""
<div style="text-align: center; padding: 2rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            border-radius: 15px; color: white; margin-top: 2rem;">
    <h4>ğŸš€ Smart Exhibition Pipeline + Google Sheets</h4>
    <p style="margin: 0.5rem 0;">
        âš¡ï¸ Rate Limiting: 4s (Ø§ÛŒÙ…Ù†) | ğŸ”’ API Limit: 15 RPM, 240/Ø±ÙˆØ²
    </p>
    <p style="margin: 0.5rem 0;">
        ğŸ“Œ Exhibition + Source Tracking | ğŸ¤– Smart Position Detection
    </p>
    <p style="margin: 0.5rem 0;">
        ğŸ“¦ Batch Processing: ØªØµØ§ÙˆÛŒØ±(5) | PDF(4) | Excel(1)
    </p>
    <p style="margin: 0.5rem 0;">
        ğŸ‘¤ Quality Control Tracking: Ù†Ø§Ù…ØŒ Ù†Ù‚Ø´ØŒ ØªØ§Ø±ÛŒØ®ØŒ Ø³Ø§Ø¹Øª
    </p>
    <p style="margin: 0.5rem 0;">
        â˜ï¸ Google Sheets: Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Drive
    </p>
    <p style="margin: 1rem 0 0 0; opacity: 0.8; font-size: 0.9rem;">
        Made with â¤ï¸ using Streamlit & Gemini AI
    </p>
</div>
""", unsafe_allow_html=True)